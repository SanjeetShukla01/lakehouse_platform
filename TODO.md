# lakehouse_platform

The goal is to create a lakehouse platform using Docker That will have following features and more
- A Lakehosue Container, having Spark Job
- An airflow Container connecting to Lakehouse to run Jobs
- Airflow container should have all the airflow health metrics recorded and displayed.
- Airflow dags with Xcom, Dynamic Dags and other latest features.
- Apache Arrow data Format
- Kubernetes
- SparkMeasure: Healthcheck and Monitoring
- Unit Test, Integration Test, Documentation Generator, Test Coverage
- CICD
- MLFlow: Machine Learning evaluation, retraining and deployment pipeline
- SQL pipeline, python sql runner
- SparkML, SparkStreaming, Kafka, Graph Processing. 


https://medium.com/@mucagriaktas/end-to-end-data-engineer-data-lake-project-scala-spark-3-5-1-150246b65d1f

