# lakehouse_platform

The goal is to create a lakehouse platform using Docker That will have following features and more
- A Lakehosue Container, having Spark Job
- An airflow Container connecting to Lakehouse to run Jobs
- Airflow container should have all the airflow health metrics recorded and displayed.
- Airflow dags with Xcom, Dynamic Dags and other latest features.
- Apache Arrow data Format
- Kubernetes
- SparkMeasure: Healthcheck and Monitoring
- Unit Test, Integration Test, Documentation Generator, Test Coverage
- CICD
- MLFlow: Machine Learning evaluation, retraining and deployment pipeline
- SQL pipeline, python sql runner
- SparkML, SparkStreaming, Kafka, Graph Processing. 
